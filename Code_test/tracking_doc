# Documentation: Système de Détection de Poses et Tracking avec YOLOv5

## Vue d'ensemble

Ce module combine la détection d'objets YOLOv5 avec MediaPipe Pose pour créer un système de surveillance avancé. Il détecte d'abord les personnes dans l'image avec YOLOv5, puis analyse leur posture avec MediaPipe Pose.

## Classe `PoseDetector`

### Initialisation

```python
detector = PoseDetector(mode=False, upBody=False, smooth=True,
                      detectionCon=0.5, trackCon=0.5)
```

- `mode`: Mode vidéo (False) ou image statique (True)
- `upBody`: Contrôle la fluidité des landmarks
- `smooth`: Active la segmentation lissée
- `detectionCon`: Seuil de confiance pour la détection (0.0-1.0)
- `trackCon`: Seuil de confiance pour le tracking (0.0-1.0)

### Méthodes principales

#### `findPose(img, draw=True)`

Détecte la pose humaine dans une image et dessine optionnellement les landmarks.
- Retourne l'image (annotée si `draw=True`)

#### `findPosition(img, draw=True)`

Extrait les coordonnées des points anatomiques détectés.
- Retourne une liste de landmarks au format `[id, x, y]`
- Dessine des cercles bleus aux positions si `draw=True`

## Fonction `main()`

Fonction de démonstration qui intègre YOLOv5 et le détecteur de poses:

1. Initialise la capture vidéo et charge le modèle YOLOv5
2. Pour chaque frame:
   - Détecte les personnes avec YOLOv5
   - Pour chaque personne détectée avec une confiance > 0.5:
     - Extrait une sous-image (crop) autour de la personne
     - Détecte la pose dans cette sous-image
     - Affiche les landmarks trouvés
   - Affiche le FPS en temps réel
3. Quitte avec la touche 'q'

## Intégration YOLOv5 et MediaPipe

Ce système en deux étapes permet:
- D'identifier précisément les personnes dans l'image (YOLOv5)
- D'analyser leur posture en détail (MediaPipe Pose)
- De traiter chaque personne séparément en cas de scènes avec plusieurs individus

## Dépendances

- OpenCV (`cv2`)
- MediaPipe (`mediapipe`)
- PyTorch (`torch`)
- YOLOv5 (chargé via torch.hub)
- Python 3.7+